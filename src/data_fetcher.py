"""
æ•°æ®è·å–æ¨¡å— - ä½¿ç”¨ CCXT ä»å¸å®‰è·å– ETHUSDT æ•°æ®
"""
import ccxt
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Tuple, List
import sqlite3
from pathlib import Path
from paths import DB_DIR, DB_PATH


class MarketDataCache:
    """SQLite ç¼“å­˜ï¼šæŒ‰ (symbol, timeframe) åˆ†è¡¨ï¼Œä¸»é”®ä¸ºæ—¶é—´æˆ³æ¯«ç§’ã€‚"""

    def __init__(self, db_path: Path = DB_PATH):
        DB_DIR.mkdir(parents=True, exist_ok=True)
        self.db_path = str(db_path)
        self._ensure_meta_table()

    def _connect(self) -> sqlite3.Connection:
        return sqlite3.connect(self.db_path)

    def _ensure_meta_table(self) -> None:
        with self._connect() as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS tables_meta (
                    id INTEGER PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    table_name TEXT NOT NULL,
                    UNIQUE(symbol, timeframe)
                )
                """
            )

    @staticmethod
    def _table_name(symbol: str, timeframe: str) -> str:
        safe_symbol = symbol.replace('/', '_').replace('-', '_').upper()
        safe_tf = timeframe.replace(' ', '').lower()
        return f"ohlcv_{safe_symbol}_{safe_tf}"

    def _ensure_data_table(self, symbol: str, timeframe: str) -> str:
        table = self._table_name(symbol, timeframe)
        with self._connect() as conn:
            conn.execute(
                f"""
                CREATE TABLE IF NOT EXISTS {table} (
                    ts INTEGER PRIMARY KEY,
                    open REAL NOT NULL,
                    high REAL NOT NULL,
                    low REAL NOT NULL,
                    close REAL NOT NULL,
                    volume REAL NOT NULL
                )
                """
            )
            conn.execute(
                "INSERT OR IGNORE INTO tables_meta(symbol, timeframe, table_name) VALUES(?,?,?)",
                (symbol, timeframe, table),
            )
        return table

    def load_range(self, symbol: str, timeframe: str, since_ms: int, limit: int) -> pd.DataFrame:
        table = self._ensure_data_table(symbol, timeframe)
        with self._connect() as conn:
            cur = conn.execute(
                f"SELECT ts, open, high, low, close, volume FROM {table} WHERE ts>=? ORDER BY ts ASC LIMIT ?",
                (since_ms, limit),
            )
            rows = cur.fetchall()
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('datetime', inplace=True)
        df.drop('timestamp', axis=1, inplace=True)
        return df

    def upsert(self, symbol: str, timeframe: str, df: pd.DataFrame) -> None:
        if df.empty:
            return
        table = self._ensure_data_table(symbol, timeframe)
        to_insert = df.copy()
        if 'timestamp' not in to_insert.columns:
            to_insert['timestamp'] = (to_insert.index.astype('int64') // 10**6).astype('int64')
        records = to_insert[['timestamp', 'open', 'high', 'low', 'close', 'volume']].itertuples(index=False)
        with self._connect() as conn:
            conn.executemany(
                f"INSERT OR REPLACE INTO {table}(ts, open, high, low, close, volume) VALUES(?,?,?,?,?,?)",
                list(records),
            )


class BinanceDataFetcher:
    """å¸å®‰æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¸å®‰äº¤æ˜“æ‰€è¿æ¥"""
        self.exchange = ccxt.binance({
            'apiKey': '',  # å¦‚æœéœ€è¦ç§æœ‰APIï¼Œåœ¨è¿™é‡Œå¡«å…¥
            'secret': '',  # å¦‚æœéœ€è¦ç§æœ‰APIï¼Œåœ¨è¿™é‡Œå¡«å…¥
            'sandbox': False,  # è®¾ç½®ä¸ºTrueä½¿ç”¨æµ‹è¯•ç¯å¢ƒ
            'enableRateLimit': True,
        })
    
    def fetch_ohlcv_data(
        self, 
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        limit: int = 500,
        since: Optional[datetime] = None
    ) -> pd.DataFrame:
        """
        è·å–OHLCVæ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œé»˜è®¤ 'ETH/USDT'
            timeframe: æ—¶é—´å‘¨æœŸï¼Œé»˜è®¤ '1h'
            limit: æ•°æ®æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤ 500
            since: å¼€å§‹æ—¶é—´ï¼Œé»˜è®¤ä¸ºNoneï¼ˆè·å–æœ€æ–°æ•°æ®ï¼‰
            
        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        try:
            # å¦‚æœæŒ‡å®šäº†å¼€å§‹æ—¶é—´ï¼Œè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
            since_timestamp = None
            if since:
                since_timestamp = int(since.timestamp() * 1000)
            
            # è·å–OHLCVæ•°æ®
            ohlcv = self.exchange.fetch_ohlcv(
                symbol=symbol,
                timeframe=timeframe,
                limit=limit,
                since=since_timestamp
            )
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸæ—¶é—´
            df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('datetime', inplace=True)
            
            # åˆ é™¤åŸå§‹æ—¶é—´æˆ³åˆ—
            df.drop('timestamp', axis=1, inplace=True)
            
            print(f"æˆåŠŸè·å– {symbol} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            print(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
            
            return df
            
        except Exception as e:
            print(f"è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return pd.DataFrame()
    
    def fetch_recent_data(
        self, 
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        days: int = 30
    ) -> pd.DataFrame:
        """
        è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´å‘¨æœŸ
            days: å¤©æ•°
            
        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        since = datetime.now() - timedelta(days=days)
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—æ•°æ®ç‚¹æ•°é‡
        if timeframe == '1h':
            limit = days * 24  # æ¯å¤©24å°æ—¶
        elif timeframe == '4h':
            limit = days * 6   # æ¯å¤©6ä¸ª4å°æ—¶Kçº¿
        elif timeframe == '12h':
            limit = days * 2   # æ¯å¤©2ä¸ª12å°æ—¶Kçº¿
        elif timeframe == '1d':
            limit = days * 1   # æ¯å¤©1ä¸ªæ—¥Kçº¿
        elif timeframe == '15m':
            limit = days * 24 * 4  # æ¯å¤©96ä¸ª15åˆ†é’ŸKçº¿
        elif timeframe == '5m':
            limit = days * 24 * 12  # æ¯å¤©288ä¸ª5åˆ†é’ŸKçº¿
        elif timeframe == '1m':
            limit = days * 24 * 60  # æ¯å¤©1440ä¸ª1åˆ†é’ŸKçº¿
        else:
            limit = days * 500  # å…¶ä»–æ—¶é—´æ¡†æ¶çš„é»˜è®¤å€¼
        return self.fetch_ohlcv_data(symbol, timeframe, limit=limit, since=since)

    def fetch_recent_with_cache(
        self,
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        days: int = 30
    ) -> pd.DataFrame:
        """ä¼˜å…ˆä»æœ¬åœ° SQLite è¯»å–ï¼Œä¸è¶³å†å¾ªç¯è¯·æ±‚è¡¥é½ï¼Œå¹¶å†™å›ç¼“å­˜ã€‚"""
        cache = MarketDataCache()
        since = datetime.now() - timedelta(days=days)
        since_ms = int(since.timestamp() * 1000)
        
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—æœŸæœ›çš„æ•°æ®ç‚¹æ•°é‡
        if timeframe == '1h':
            expected_records = days * 24  # æ¯å¤©24å°æ—¶
        elif timeframe == '4h':
            expected_records = days * 6   # æ¯å¤©6ä¸ª4å°æ—¶Kçº¿
        elif timeframe == '12h':
            expected_records = days * 2   # æ¯å¤©2ä¸ª12å°æ—¶Kçº¿
        elif timeframe == '1d':
            expected_records = days * 1   # æ¯å¤©1ä¸ªæ—¥Kçº¿
        elif timeframe == '15m':
            expected_records = days * 24 * 4  # æ¯å¤©96ä¸ª15åˆ†é’ŸKçº¿
        elif timeframe == '5m':
            expected_records = days * 24 * 12  # æ¯å¤©288ä¸ª5åˆ†é’ŸKçº¿
        elif timeframe == '1m':
            expected_records = days * 24 * 60  # æ¯å¤©1440ä¸ª1åˆ†é’ŸKçº¿
        else:
            expected_records = days * 500  # å…¶ä»–æ—¶é—´æ¡†æ¶çš„é»˜è®¤å€¼

        print(f"æœŸæœ›è·å– {expected_records} æ¡ {timeframe} æ•°æ® (æœ€è¿‘{days}å¤©)")

        # 1) å…ˆè¯»ç¼“å­˜
        cached = cache.load_range(symbol, timeframe, since_ms, expected_records * 2)  # å¤šè¯»ä¸€äº›é¿å…è¾¹ç•Œé—®é¢˜
        cached_in_range = cached[cached.index >= since] if not cached.empty else cached
        print(f"ä»ç¼“å­˜ä¸­è¯»å–åˆ° {len(cached_in_range)} æ¡ç›®æ ‡æ—¶é—´èŒƒå›´å†…çš„è®°å½•")

        # 2) å¦‚æœç¼“å­˜æ•°æ®è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
        if len(cached_in_range) >= expected_records * 0.95:  # å…è®¸5%çš„è¯¯å·®
            print(f"ç¼“å­˜æ•°æ®å……è¶³ï¼Œè¿”å› {len(cached_in_range)} æ¡è®°å½•")
            return cached_in_range.head(expected_records)

        # 3) ç¼“å­˜ä¸è¶³ï¼Œéœ€è¦å¾ªç¯è·å–ï¼ˆå‘æ›´æ—©çš„æ—¶é—´å›è¡¥ï¼‰
        print(f"ç¼“å­˜ä¸è¶³ï¼Œéœ€è¦å¾ªç¯è·å–æ›´å¤šæ•°æ®...")
        
        all_data = []
        if not cached_in_range.empty:
            all_data.append(cached_in_range)
        
        # ä»¥ç¼“å­˜ä¸­æœ€æ—©ä¸€æ ¹Kçº¿ä¸ºç•Œï¼Œå‘æ›´æ—©æ–¹å‘æŠ“å–
        timeframe_minutes = {
            '1m': 1, '5m': 5, '15m': 15, '30m': 30,
            '1h': 60, '4h': 240, '12h': 720, '1d': 1440,
        }
        interval_delta = timedelta(minutes=timeframe_minutes.get(timeframe, 60))
        earliest_time = cached_in_range.index.min() if not cached_in_range.empty else None
        batch_size = 1000  # å•æ‰¹æœ€å¤§æ¡æ•°
        batch_count = 0
        
        import time
        
        # å¾ªç¯æ¡ä»¶ï¼šå°šæœªè¦†ç›–åˆ°èµ·å§‹æ—¶é—´ï¼Œä¸”å°šæœªè¾¾åˆ°æœŸæœ›æ¡æ•°ï¼Œä¸”æ‰¹æ¬¡æ•°é™åˆ¶å†…
        while (
            batch_count < 20 and
            (earliest_time is None or earliest_time > since)
        ):
            batch_count += 1
            # ç›®æ ‡æ‰¹é‡ï¼šå°½é‡æ»¡æ‰¹ï¼Œå¤šå–å°‘è¡¥
            current_batch_size = batch_size
            print(f"ç¬¬{batch_count}æ‰¹ï¼šå°è¯•è·å– {current_batch_size} æ¡è®°å½•...")
            
            # è®¡ç®— sinceï¼šä¸ºäº†ä¸ç•™ç©ºæ´ï¼Œä½¿ç”¨â€œcurrent_batch_size - overlapâ€ç­–ç•¥
            overlap_records = 50
            if earliest_time is None:
                # æ²¡æœ‰ç¼“å­˜ï¼Œç›´æ¥ä»ç›®æ ‡èµ·ç‚¹å¼€å§‹
                batch_since = since
            else:
                step_records = max(current_batch_size - overlap_records, 1)
                batch_since = earliest_time - interval_delta * step_records
            
            # è·å–è¿™æ‰¹æ•°æ®
            batch_data = self.fetch_ohlcv_data(
                symbol=symbol,
                timeframe=timeframe,
                limit=current_batch_size,
                since=batch_since
            )
            
            if batch_data.empty:
                print(f"ç¬¬{batch_count}æ‰¹è·å–å¤±è´¥æˆ–æ— æ•°æ®ï¼Œåœæ­¢è·å–")
                break
            
            # ä»…ä¿ç•™ç›®æ ‡æ—¶é—´èŒƒå›´å†…ä¸”æ—©äºå½“å‰å·²çŸ¥æœ€æ—©è¾¹ç•Œçš„æ•°æ®ï¼Œé¿å…é‡å¤
            if earliest_time is None:
                batch_filtered = batch_data[batch_data.index >= since]
            else:
                batch_filtered = batch_data[(batch_data.index >= since) & (batch_data.index < earliest_time)]
            
            if not batch_filtered.empty:
                all_data.append(batch_filtered)
                # æ›´æ–°æœ€æ—©è¾¹ç•Œä¸ºâ€œæœ¬æ‰¹æœ€æ—©æ—¶é—´â€ï¼Œç¡®ä¿ä¸‹æ¬¡ since åŸºäºçœŸå®è¾¹ç•Œè®¡ç®—
                earliest_time = batch_filtered.index.min()
                print(f"ç¬¬{batch_count}æ‰¹è·å–åˆ° {len(batch_filtered)} æ¡æœ‰æ•ˆè®°å½•ï¼Œæœ€æ—©æ—¶é—´æ¨è¿›è‡³ {earliest_time}")
            else:
                print(f"ç¬¬{batch_count}æ‰¹æ— æ–°å¢æœ‰æ•ˆè®°å½•ï¼ˆå¯èƒ½ä¸ºå®Œå…¨é‡å ï¼‰ï¼Œç»§ç»­å‘å‰å°è¯•")
                # å¦‚æœæ²¡æœ‰æ–°çš„æ›´æ—©æ•°æ®ï¼Œå°è¯•ç›´æ¥æŠŠ earliest_time å†å‘å‰æ¨è¿›ä¸€æ®µï¼Œé¿å…åœæ»
                if earliest_time is not None:
                    earliest_time = earliest_time - interval_delta * max((current_batch_size // 4), 1)
            
            # å·²è¦†ç›–åˆ°ç›®æ ‡èµ·ç‚¹å³å¯é€€å‡º
            if earliest_time is not None and earliest_time <= since:
                break
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.25)
        
        # 4) åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            combined = pd.concat(all_data).sort_index()
            # å»é‡ï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
            combined = combined[~combined.index.duplicated(keep='last')]
            # ä»…ä¿ç•™ç›®æ ‡æ—¶é—´èŒƒå›´
            combined = combined[combined.index >= since]
            
            # å¦‚æœæ•°æ®å¤šäºæœŸæœ›æ•°é‡ï¼Œæˆªæ–­åˆ°æœŸæœ›è§„æ¨¡ï¼ˆä»æœ€æ–°å¾€å›ï¼‰
            if len(combined) > expected_records:
                combined = combined.tail(expected_records)
            
            print(f"æœ€ç»ˆè·å¾— {len(combined)} æ¡è®°å½•ï¼Œæ—¶é—´èŒƒå›´ï¼š{combined.index.min()} åˆ° {combined.index.max()}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            cache.upsert(symbol, timeframe, combined)
            return combined
        else:
            print("æœªèƒ½è·å–åˆ°æ–°æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
            return cached_in_range
    
    def check_data_integrity(self, data: pd.DataFrame, timeframe: str, expected_days: int, expected_since: Optional[datetime] = None, expected_until: Optional[datetime] = None) -> Tuple[bool, List[Tuple[datetime, datetime]]]:
        """
        æ£€æŸ¥Kçº¿æ•°æ®çš„å®Œæ•´æ€§ï¼Œè¿”å›æ˜¯å¦å®Œæ•´å’Œç¼ºå¤±çš„æ—¶é—´æ®µ
        
        Args:
            data: Kçº¿æ•°æ®DataFrameï¼Œç´¢å¼•ä¸ºæ—¶é—´
            timeframe: æ—¶é—´æ¡†æ¶ ('1h', '4h', '1d' ç­‰)
            expected_days: æœŸæœ›çš„å¤©æ•°
            
        Returns:
            Tuple[bool, List[Tuple[datetime, datetime]]]: (æ˜¯å¦å®Œæ•´, ç¼ºå¤±æ—¶é—´æ®µåˆ—è¡¨)
        """
        if data.empty:
            return False, []
        
        # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        timeframe_minutes = {
            '1m': 1,
            '5m': 5,
            '15m': 15,
            '30m': 30,
            '1h': 60,
            '4h': 240,
            '12h': 720,
            '1d': 1440,
        }
        
        if timeframe not in timeframe_minutes:
            print(f"âš ï¸ ä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶: {timeframe}")
            return True, []  # å¯¹äºä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶ï¼Œå‡è®¾å®Œæ•´
        
        interval_minutes = timeframe_minutes[timeframe]
        interval_delta = timedelta(minutes=interval_minutes)
        
        # æœŸæœ›è¦†ç›–çš„æ—¶é—´èŒƒå›´ï¼šå…è®¸æŒ‡å®šè¾¹ç•Œï¼›æœªæŒ‡å®šæ—¶ä½¿ç”¨æ•°æ®è¾¹ç•Œ
        raw_start = expected_since if expected_since is not None else data.index.min()
        raw_end = expected_until if expected_until is not None else data.index.max()
        
        print(f"ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
        print(f"   æ—¶é—´æ¡†æ¶: {timeframe}")
        
        # å°†æœŸæœ›è¾¹ç•Œå¯¹é½åˆ°æ—¶é—´æ¡†æ¶ç½‘æ ¼ï¼Œé¿å…æŠŠå…¨éƒ¨æ•°æ®è¯¯åˆ¤ä¸ºç¼ºå¤±
        # ä¾‹å¦‚ 4h æ¡†æ¶ï¼Œç½‘æ ¼ä¸º 00:00/04:00/08:00/12:00/16:00/20:00
        import math
        epoch = datetime(1970, 1, 1)
        interval_minutes = timeframe_minutes[timeframe]
        interval_seconds = interval_minutes * 60
        
        def align(dt: datetime, mode: str) -> datetime:
            delta_sec = (dt - epoch).total_seconds()
            if mode == 'floor':
                aligned = math.floor(delta_sec / interval_seconds) * interval_seconds
            else:  # ceil
                aligned = math.ceil(delta_sec / interval_seconds) * interval_seconds
            return epoch + timedelta(seconds=aligned)
        
        start_time = align(raw_start, 'ceil')
        end_time = align(raw_end, 'floor')
        
        print(f"   æ•°æ®èŒƒå›´(å¯¹é½å‰): {raw_start} åˆ° {raw_end}")
        print(f"   æ•°æ®èŒƒå›´(å¯¹é½å): {start_time} åˆ° {end_time}")
        print(f"   å®é™…è®°å½•æ•°: {len(data)}")
        
        # ç”ŸæˆæœŸæœ›çš„æ—¶é—´åºåˆ—ï¼ˆä¸¥æ ¼åœ¨ç½‘æ ¼ä¸Šï¼‰
        expected_times = []
        current_time = start_time
        while current_time <= end_time:
            expected_times.append(current_time)
            current_time += interval_delta
        
        expected_count = len(expected_times)
        print(f"   æœŸæœ›è®°å½•æ•°: {expected_count}")
        
        # æ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´ç‚¹
        data_times = set(data.index)
        expected_times_set = set(expected_times)
        missing_times = sorted(expected_times_set - data_times)
        
        if not missing_times:
            print(f"âœ… æ•°æ®å®Œæ•´ï¼Œæ— ç¼ºå¤±")
            return True, []
        
        # å°†è¿ç»­çš„ç¼ºå¤±æ—¶é—´åˆå¹¶ä¸ºæ—¶é—´æ®µ
        missing_ranges = []
        if missing_times:
            range_start = missing_times[0]
            range_end = missing_times[0]
            
            for i in range(1, len(missing_times)):
                current_time = missing_times[i]
                expected_next = range_end + interval_delta
                
                if current_time == expected_next:
                    # è¿ç»­ç¼ºå¤±ï¼Œæ‰©å±•å½“å‰èŒƒå›´
                    range_end = current_time
                else:
                    # ä¸è¿ç»­ï¼Œä¿å­˜å½“å‰èŒƒå›´å¹¶å¼€å§‹æ–°èŒƒå›´
                    missing_ranges.append((range_start, range_end))
                    range_start = current_time
                    range_end = current_time
            
            # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
            missing_ranges.append((range_start, range_end))
        
        missing_count = len(missing_times)
        completeness = (expected_count - missing_count) / expected_count * 100 if expected_count > 0 else 100.0
        
        print(f"âš ï¸ æ•°æ®ä¸å®Œæ•´:")
        print(f"   ç¼ºå¤±è®°å½•æ•°: {missing_count}")
        print(f"   å®Œæ•´åº¦: {completeness:.1f}%")
        print(f"   ç¼ºå¤±æ—¶é—´æ®µæ•°: {len(missing_ranges)}")
        
        for i, (start, end) in enumerate(missing_ranges[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªç¼ºå¤±æ®µ
            if start == end:
                print(f"   ç¼ºå¤±æ®µ {i+1}: {start}")
            else:
                print(f"   ç¼ºå¤±æ®µ {i+1}: {start} åˆ° {end}")
        
        if len(missing_ranges) > 5:
            print(f"   ... è¿˜æœ‰ {len(missing_ranges) - 5} ä¸ªç¼ºå¤±æ®µ")
        
        # è¾¹ç•Œæç¤ºï¼šå¦‚æœåŸå§‹èµ·ç‚¹ä¸åœ¨ç½‘æ ¼ä¸Šï¼Œæç¤ºä½†ä¸è®¡å…¥ç¼ºå£ï¼ˆæ— å®é™…Kçº¿å¯è¡¥ï¼‰
        if expected_since is not None and raw_start != start_time:
            print(f"   æ³¨æ„: æœŸæœ›èµ·ç‚¹ {raw_start} æœªå¯¹é½åˆ° {timeframe} ç½‘æ ¼ï¼Œå·²å¯¹é½ä¸º {start_time}")
        if expected_until is not None and raw_end != end_time:
            print(f"   æ³¨æ„: æœŸæœ›ç»ˆç‚¹ {raw_end} æœªå¯¹é½åˆ° {timeframe} ç½‘æ ¼ï¼Œå·²å¯¹é½ä¸º {end_time}")
        
        return False, missing_ranges
    
    def fill_missing_data(self, data: pd.DataFrame, symbol: str, timeframe: str, 
                         missing_ranges: List[Tuple[datetime, datetime]]) -> pd.DataFrame:
        """
        è¡¥å……ç¼ºå¤±çš„Kçº¿æ•°æ®
        
        Args:
            data: ç°æœ‰çš„Kçº¿æ•°æ®
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            missing_ranges: ç¼ºå¤±çš„æ—¶é—´æ®µåˆ—è¡¨
            
        Returns:
            è¡¥å……åçš„å®Œæ•´æ•°æ®
        """
        if not missing_ranges:
            return data
        
        print(f"ğŸ”„ å¼€å§‹è¡¥å……ç¼ºå¤±æ•°æ®...")
        cache = MarketDataCache()
        all_data = [data] if not data.empty else []
        
        for i, (start_time, end_time) in enumerate(missing_ranges):
            print(f"   è¡¥å……ç¼ºå¤±æ®µ {i+1}/{len(missing_ranges)}: {start_time} åˆ° {end_time}")
            
            # ç²’åº¦ä¸æ­¥é•¿
            timeframe_minutes = {
                '1m': 1, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '4h': 240, '12h': 720, '1d': 1440,
            }
            
            if timeframe not in timeframe_minutes:
                print(f"   âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶: {timeframe}")
                continue
            
            interval_minutes = timeframe_minutes[timeframe]
            interval_delta = timedelta(minutes=interval_minutes)
            
            # åˆ†é¡µå¾ªç¯æŠ“å–ç›´åˆ°è¦†ç›–æ•´ä¸ªç¼ºå£
            current_since = start_time - interval_delta * 2  # å°ç¼“å†²é¿å…è¾¹ç•Œé—æ¼
            page_count = 0
            last_progress_ts = None
            
            import time
            
            while current_since <= end_time and page_count < 50:  # ç»™å‡ºåˆç†ä¸Šé™é˜²æ­¢æ­»å¾ªç¯
                page_count += 1
                try:
                    batch = self.fetch_ohlcv_data(
                        symbol=symbol,
                        timeframe=timeframe,
                        limit=1000,
                        since=current_since
                    )
                    
                    if batch.empty:
                        print(f"      ç¬¬{page_count}é¡µæ— æ•°æ®ï¼Œåœæ­¢æœ¬ç¼ºå£æŠ“å–")
                        break
                    
                    # è¿‡æ»¤åˆ°ç›®æ ‡ç¼ºå£èŒƒå›´
                    batch_filtered = batch[(batch.index >= start_time) & (batch.index <= end_time)]
                    if not batch_filtered.empty:
                        all_data.append(batch_filtered)
                        print(f"      ç¬¬{page_count}é¡µè¡¥å…¥ {len(batch_filtered)} æ¡")
                        # å†™å›ç¼“å­˜ï¼ˆä½¿ç”¨åŸbatchï¼‰
                        cache.upsert(symbol, timeframe, batch)
                    
                    # æ¨è¿›æ¸¸æ ‡
                    max_ts = batch.index.max()
                    if last_progress_ts is not None and max_ts <= last_progress_ts:
                        # æ²¡æœ‰å‰è¿›ï¼Œå¼ºè¡Œæ¨è¿›ä¸€æ ¼é˜²æ­¢å¡ä½
                        max_ts = last_progress_ts + interval_delta
                    last_progress_ts = max_ts
                    current_since = max_ts + interval_delta
                    
                    # å·²è¦†ç›–åˆ°ç¼ºå£æœ«å°¾åˆ™é€€å‡º
                    if current_since > end_time:
                        break
                    
                    # é™é€Ÿ
                    time.sleep(0.25)
                except Exception as e:
                    print(f"      æŠ“å–ç¬¬{page_count}é¡µå‡ºé”™: {e}")
                    break
            
            # å°é—´éš”é¿å…è¿‡äºé¢‘ç¹
            time.sleep(0.3)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if len(all_data) > 1:
            combined_data = pd.concat(all_data, axis=0)
            # å»é‡å¹¶æ’åº
            combined_data = combined_data[~combined_data.index.duplicated(keep='first')]
            combined_data = combined_data.sort_index()
            
            print(f"âœ… æ•°æ®è¡¥å……å®Œæˆï¼Œæœ€ç»ˆæ•°æ®é‡: {len(combined_data)} æ¡")
            return combined_data
        else:
            return data
    
    def fetch_complete_data(self, symbol: str = 'ETH/USDT', timeframe: str = '4h', 
                           days: int = 730) -> pd.DataFrame:
        """
        è·å–å®Œæ•´çš„Kçº¿æ•°æ®ï¼ŒåŒ…å«å®Œæ•´æ€§æ£€æŸ¥å’Œç¼ºå¤±æ•°æ®è¡¥å……
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            days: å¤©æ•°
            
        Returns:
            å®Œæ•´çš„Kçº¿æ•°æ®
        """
        print(f"ğŸ“ˆ è·å–å®Œæ•´çš„ {symbol} {timeframe} æ•°æ® (æœ€è¿‘{days}å¤©)")
        
        # 1. é¦–å…ˆä½¿ç”¨ç°æœ‰æ–¹æ³•è·å–æ•°æ®
        data = self.fetch_recent_with_cache(symbol, timeframe, days)
        
        if data.empty:
            print("âŒ æ— æ³•è·å–åŸºç¡€æ•°æ®")
            return data
        
        # 2. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆè¦†ç›–ç›®æ ‡èµ·ç‚¹åˆ°ç°æœ‰æœ«å°¾ï¼‰
        expected_since = datetime.now() - timedelta(days=days)
        is_complete, missing_ranges = self.check_data_integrity(data, timeframe, days, expected_since=expected_since)
        
        # 3. å¦‚æœæ•°æ®ä¸å®Œæ•´ï¼Œè¡¥å……ç¼ºå¤±æ•°æ®
        if not is_complete and missing_ranges:
            data = self.fill_missing_data(data, symbol, timeframe, missing_ranges)
            
            # 4. å†æ¬¡æ£€æŸ¥å®Œæ•´æ€§
            print(f"\nğŸ” è¡¥å……åå†æ¬¡æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
            final_is_complete, final_missing = self.check_data_integrity(data, timeframe, days)
            
            if final_is_complete:
                print(f"âœ… æ•°æ®è¡¥å……æˆåŠŸï¼Œç°åœ¨æ•°æ®å®Œæ•´")
            else:
                print(f"âš ï¸ ä»æœ‰ {len(final_missing)} ä¸ªæ—¶é—´æ®µç¼ºå¤±æ•°æ®")
        
        return data


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®è·å–
    fetcher = BinanceDataFetcher()
    data = fetcher.fetch_recent_data(days=7)
    
    if not data.empty:
        print("\næ•°æ®é¢„è§ˆ:")
        print(data.head())
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(data.describe())
