"""
æ•°æ®è·å–æ¨¡å— - ä½¿ç”¨ CCXT ä»å¸å®‰è·å– ETHUSDT æ•°æ®
"""
import ccxt
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Tuple, List
import sqlite3
from pathlib import Path
from paths import DB_DIR, DB_PATH


class MarketDataCache:
    """SQLite ç¼“å­˜ï¼šæŒ‰ (symbol, timeframe) åˆ†è¡¨ï¼Œä¸»é”®ä¸ºæ—¶é—´æˆ³æ¯«ç§’ã€‚"""

    def __init__(self, db_path: Path = DB_PATH):
        DB_DIR.mkdir(parents=True, exist_ok=True)
        self.db_path = str(db_path)
        self._ensure_meta_table()

    def _connect(self) -> sqlite3.Connection:
        return sqlite3.connect(self.db_path)

    def _ensure_meta_table(self) -> None:
        with self._connect() as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS tables_meta (
                    id INTEGER PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    table_name TEXT NOT NULL,
                    UNIQUE(symbol, timeframe)
                )
                """
            )

    @staticmethod
    def _table_name(symbol: str, timeframe: str) -> str:
        safe_symbol = symbol.replace('/', '_').replace('-', '_').upper()
        safe_tf = timeframe.replace(' ', '').lower()
        return f"ohlcv_{safe_symbol}_{safe_tf}"

    def _ensure_data_table(self, symbol: str, timeframe: str) -> str:
        table = self._table_name(symbol, timeframe)
        with self._connect() as conn:
            conn.execute(
                f"""
                CREATE TABLE IF NOT EXISTS {table} (
                    ts INTEGER PRIMARY KEY,
                    open REAL NOT NULL,
                    high REAL NOT NULL,
                    low REAL NOT NULL,
                    close REAL NOT NULL,
                    volume REAL NOT NULL
                )
                """
            )
            conn.execute(
                "INSERT OR IGNORE INTO tables_meta(symbol, timeframe, table_name) VALUES(?,?,?)",
                (symbol, timeframe, table),
            )
        return table

    def load_range(self, symbol: str, timeframe: str, since_ms: int, limit: int) -> pd.DataFrame:
        table = self._ensure_data_table(symbol, timeframe)
        with self._connect() as conn:
            cur = conn.execute(
                f"SELECT ts, open, high, low, close, volume FROM {table} WHERE ts>=? ORDER BY ts ASC LIMIT ?",
                (since_ms, limit),
            )
            rows = cur.fetchall()
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('datetime', inplace=True)
        df.drop('timestamp', axis=1, inplace=True)
        return df

    def upsert(self, symbol: str, timeframe: str, df: pd.DataFrame) -> None:
        if df.empty:
            return
        table = self._ensure_data_table(symbol, timeframe)
        to_insert = df.copy()
        if 'timestamp' not in to_insert.columns:
            to_insert['timestamp'] = (to_insert.index.astype('int64') // 10**6).astype('int64')
        records = to_insert[['timestamp', 'open', 'high', 'low', 'close', 'volume']].itertuples(index=False)
        with self._connect() as conn:
            conn.executemany(
                f"INSERT OR REPLACE INTO {table}(ts, open, high, low, close, volume) VALUES(?,?,?,?,?,?)",
                list(records),
            )


class BinanceDataFetcher:
    """å¸å®‰æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¸å®‰äº¤æ˜“æ‰€è¿æ¥"""
        self.exchange = ccxt.binance({
            'apiKey': '',  # å¦‚æœéœ€è¦ç§æœ‰APIï¼Œåœ¨è¿™é‡Œå¡«å…¥
            'secret': '',  # å¦‚æœéœ€è¦ç§æœ‰APIï¼Œåœ¨è¿™é‡Œå¡«å…¥
            'sandbox': False,  # è®¾ç½®ä¸ºTrueä½¿ç”¨æµ‹è¯•ç¯å¢ƒ
            'enableRateLimit': True,
        })
    
    def fetch_ohlcv_data(
        self, 
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        limit: int = 500,
        since: Optional[datetime] = None
    ) -> pd.DataFrame:
        """
        è·å–OHLCVæ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œé»˜è®¤ 'ETH/USDT'
            timeframe: æ—¶é—´å‘¨æœŸï¼Œé»˜è®¤ '1h'
            limit: æ•°æ®æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤ 500
            since: å¼€å§‹æ—¶é—´ï¼Œé»˜è®¤ä¸ºNoneï¼ˆè·å–æœ€æ–°æ•°æ®ï¼‰
            
        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        try:
            # å¦‚æœæŒ‡å®šäº†å¼€å§‹æ—¶é—´ï¼Œè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
            since_timestamp = None
            if since:
                since_timestamp = int(since.timestamp() * 1000)
            
            # è·å–OHLCVæ•°æ®
            ohlcv = self.exchange.fetch_ohlcv(
                symbol=symbol,
                timeframe=timeframe,
                limit=limit,
                since=since_timestamp
            )
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸæ—¶é—´
            df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('datetime', inplace=True)
            
            # åˆ é™¤åŸå§‹æ—¶é—´æˆ³åˆ—
            df.drop('timestamp', axis=1, inplace=True)
            
            print(f"æˆåŠŸè·å– {symbol} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            print(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
            
            return df
            
        except Exception as e:
            print(f"è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return pd.DataFrame()
    
    def fetch_recent_data(
        self, 
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        days: int = 30
    ) -> pd.DataFrame:
        """
        è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´å‘¨æœŸ
            days: å¤©æ•°
            
        Returns:
            åŒ…å«OHLCVæ•°æ®çš„DataFrame
        """
        since = datetime.now() - timedelta(days=days)
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—æ•°æ®ç‚¹æ•°é‡
        if timeframe == '1h':
            limit = days * 24  # æ¯å¤©24å°æ—¶
        elif timeframe == '4h':
            limit = days * 6   # æ¯å¤©6ä¸ª4å°æ—¶Kçº¿
        elif timeframe == '12h':
            limit = days * 2   # æ¯å¤©2ä¸ª12å°æ—¶Kçº¿
        elif timeframe == '1d':
            limit = days * 1   # æ¯å¤©1ä¸ªæ—¥Kçº¿
        elif timeframe == '15m':
            limit = days * 24 * 4  # æ¯å¤©96ä¸ª15åˆ†é’ŸKçº¿
        elif timeframe == '5m':
            limit = days * 24 * 12  # æ¯å¤©288ä¸ª5åˆ†é’ŸKçº¿
        elif timeframe == '1m':
            limit = days * 24 * 60  # æ¯å¤©1440ä¸ª1åˆ†é’ŸKçº¿
        else:
            limit = days * 500  # å…¶ä»–æ—¶é—´æ¡†æ¶çš„é»˜è®¤å€¼
        return self.fetch_ohlcv_data(symbol, timeframe, limit=limit, since=since)

    def fetch_recent_with_cache(
        self,
        symbol: str = 'ETH/USDT',
        timeframe: str = '1h',
        days: int = 30
    ) -> pd.DataFrame:
        """ä¼˜å…ˆä»æœ¬åœ° SQLite è¯»å–ï¼Œä¸è¶³å†å¾ªç¯è¯·æ±‚è¡¥é½ï¼Œå¹¶å†™å›ç¼“å­˜ã€‚"""
        cache = MarketDataCache()
        since = datetime.now() - timedelta(days=days)
        since_ms = int(since.timestamp() * 1000)
        
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—æœŸæœ›çš„æ•°æ®ç‚¹æ•°é‡
        if timeframe == '1h':
            expected_records = days * 24  # æ¯å¤©24å°æ—¶
        elif timeframe == '4h':
            expected_records = days * 6   # æ¯å¤©6ä¸ª4å°æ—¶Kçº¿
        elif timeframe == '12h':
            expected_records = days * 2   # æ¯å¤©2ä¸ª12å°æ—¶Kçº¿
        elif timeframe == '1d':
            expected_records = days * 1   # æ¯å¤©1ä¸ªæ—¥Kçº¿
        elif timeframe == '15m':
            expected_records = days * 24 * 4  # æ¯å¤©96ä¸ª15åˆ†é’ŸKçº¿
        elif timeframe == '5m':
            expected_records = days * 24 * 12  # æ¯å¤©288ä¸ª5åˆ†é’ŸKçº¿
        elif timeframe == '1m':
            expected_records = days * 24 * 60  # æ¯å¤©1440ä¸ª1åˆ†é’ŸKçº¿
        else:
            expected_records = days * 500  # å…¶ä»–æ—¶é—´æ¡†æ¶çš„é»˜è®¤å€¼

        print(f"æœŸæœ›è·å– {expected_records} æ¡ {timeframe} æ•°æ® (æœ€è¿‘{days}å¤©)")

        # 1) å…ˆè¯»ç¼“å­˜
        cached = cache.load_range(symbol, timeframe, since_ms, expected_records * 2)  # å¤šè¯»ä¸€äº›é¿å…è¾¹ç•Œé—®é¢˜
        cached_in_range = cached[cached.index >= since] if not cached.empty else cached
        print(f"ä»ç¼“å­˜ä¸­è¯»å–åˆ° {len(cached_in_range)} æ¡ç›®æ ‡æ—¶é—´èŒƒå›´å†…çš„è®°å½•")

        # 2) å¦‚æœç¼“å­˜æ•°æ®è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
        if len(cached_in_range) >= expected_records * 0.95:  # å…è®¸5%çš„è¯¯å·®
            print(f"ç¼“å­˜æ•°æ®å……è¶³ï¼Œè¿”å› {len(cached_in_range)} æ¡è®°å½•")
            return cached_in_range.head(expected_records)

        # 3) ç¼“å­˜ä¸è¶³ï¼Œéœ€è¦å¾ªç¯è·å–
        print(f"ç¼“å­˜ä¸è¶³ï¼Œéœ€è¦å¾ªç¯è·å–æ›´å¤šæ•°æ®...")
        
        all_data = []
        if not cached_in_range.empty:
            all_data.append(cached_in_range)
        
        # ä»æœ€æ—©éœ€è¦çš„æ—¶é—´å¼€å§‹ï¼Œåˆ†æ‰¹å‘å‰è·å–
        current_end_time = datetime.now()
        batch_size = 1000  # æ¯æ‰¹æœ€å¤š1000æ¡
        total_collected = len(cached_in_range)
        batch_count = 0
        
        import time
        
        while total_collected < expected_records and batch_count < 10:  # æœ€å¤š10æ‰¹ï¼Œé¿å…æ— é™å¾ªç¯
            batch_count += 1
            
            # è®¡ç®—è¿™æ‰¹éœ€è¦è·å–å¤šå°‘æ¡
            remaining = expected_records - total_collected
            current_batch_size = min(batch_size, remaining + 200)  # å¤šè·å–ä¸€äº›é¿å…è¾¹ç•Œé—®é¢˜
            
            print(f"ç¬¬{batch_count}æ‰¹ï¼šå°è¯•è·å– {current_batch_size} æ¡è®°å½•...")
            
            # è®¡ç®—è¿™æ‰¹æ•°æ®çš„å¼€å§‹æ—¶é—´
            if timeframe == '4h':
                batch_days = (current_batch_size // 6) + 10  # 4å°æ—¶çº¿ï¼Œæ¯å¤©6æ¡ï¼Œå¤šåŠ 10å¤©ç¼“å†²
            elif timeframe == '1h':
                batch_days = (current_batch_size // 24) + 5   # 1å°æ—¶çº¿ï¼Œæ¯å¤©24æ¡
            elif timeframe == '1d':
                batch_days = current_batch_size + 10          # æ—¥çº¿
            else:
                batch_days = 100  # å…¶ä»–æ—¶é—´æ¡†æ¶çš„é»˜è®¤å€¼
                
            batch_since = current_end_time - timedelta(days=batch_days)
            
            # è·å–è¿™æ‰¹æ•°æ®
            batch_data = self.fetch_ohlcv_data(
                symbol=symbol,
                timeframe=timeframe,
                limit=current_batch_size,
                since=batch_since
            )
            
            if batch_data.empty:
                print(f"ç¬¬{batch_count}æ‰¹è·å–å¤±è´¥ï¼Œåœæ­¢è·å–")
                break
            
            # è¿‡æ»¤åˆ°ç›®æ ‡æ—¶é—´èŒƒå›´
            batch_in_range = batch_data[batch_data.index >= since]
            if not batch_in_range.empty:
                all_data.append(batch_in_range)
                total_collected += len(batch_in_range)
                print(f"ç¬¬{batch_count}æ‰¹è·å–åˆ° {len(batch_in_range)} æ¡æœ‰æ•ˆè®°å½•ï¼Œæ€»è®¡ {total_collected} æ¡")
            
            # æ›´æ–°ä¸‹æ¬¡è·å–çš„ç»“æŸæ—¶é—´
            current_end_time = batch_data.index.min() - timedelta(hours=1)
            
            # å¦‚æœå·²ç»è·å–åˆ°è¶³å¤Ÿæ—©çš„æ•°æ®ï¼Œåœæ­¢
            if current_end_time <= since:
                break
                
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.2)
        
        # 4) åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            combined = pd.concat(all_data).sort_index()
            # å»é‡ï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
            combined = combined[~combined.index.duplicated(keep='last')]
            # ç¡®ä¿åœ¨ç›®æ ‡æ—¶é—´èŒƒå›´å†…
            combined = combined[combined.index >= since]
            
            print(f"æœ€ç»ˆè·å¾— {len(combined)} æ¡è®°å½•ï¼Œæ—¶é—´èŒƒå›´ï¼š{combined.index.min()} åˆ° {combined.index.max()}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            cache.upsert(symbol, timeframe, combined)
            return combined
        else:
            print("æœªèƒ½è·å–åˆ°æ–°æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
            return cached_in_range
    
    def check_data_integrity(self, data: pd.DataFrame, timeframe: str, expected_days: int) -> Tuple[bool, List[Tuple[datetime, datetime]]]:
        """
        æ£€æŸ¥Kçº¿æ•°æ®çš„å®Œæ•´æ€§ï¼Œè¿”å›æ˜¯å¦å®Œæ•´å’Œç¼ºå¤±çš„æ—¶é—´æ®µ
        
        Args:
            data: Kçº¿æ•°æ®DataFrameï¼Œç´¢å¼•ä¸ºæ—¶é—´
            timeframe: æ—¶é—´æ¡†æ¶ ('1h', '4h', '1d' ç­‰)
            expected_days: æœŸæœ›çš„å¤©æ•°
            
        Returns:
            Tuple[bool, List[Tuple[datetime, datetime]]]: (æ˜¯å¦å®Œæ•´, ç¼ºå¤±æ—¶é—´æ®µåˆ—è¡¨)
        """
        if data.empty:
            return False, []
        
        # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        timeframe_minutes = {
            '1m': 1,
            '5m': 5,
            '15m': 15,
            '30m': 30,
            '1h': 60,
            '4h': 240,
            '12h': 720,
            '1d': 1440,
        }
        
        if timeframe not in timeframe_minutes:
            print(f"âš ï¸ ä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶: {timeframe}")
            return True, []  # å¯¹äºä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶ï¼Œå‡è®¾å®Œæ•´
        
        interval_minutes = timeframe_minutes[timeframe]
        interval_delta = timedelta(minutes=interval_minutes)
        
        # è·å–æ•°æ®çš„æ—¶é—´èŒƒå›´
        start_time = data.index.min()
        end_time = data.index.max()
        
        print(f"ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
        print(f"   æ—¶é—´æ¡†æ¶: {timeframe}")
        print(f"   æ•°æ®èŒƒå›´: {start_time} åˆ° {end_time}")
        print(f"   å®é™…è®°å½•æ•°: {len(data)}")
        
        # ç”ŸæˆæœŸæœ›çš„æ—¶é—´åºåˆ—
        expected_times = []
        current_time = start_time
        while current_time <= end_time:
            expected_times.append(current_time)
            current_time += interval_delta
        
        expected_count = len(expected_times)
        print(f"   æœŸæœ›è®°å½•æ•°: {expected_count}")
        
        # æ‰¾å‡ºç¼ºå¤±çš„æ—¶é—´ç‚¹
        data_times = set(data.index)
        expected_times_set = set(expected_times)
        missing_times = sorted(expected_times_set - data_times)
        
        if not missing_times:
            print(f"âœ… æ•°æ®å®Œæ•´ï¼Œæ— ç¼ºå¤±")
            return True, []
        
        # å°†è¿ç»­çš„ç¼ºå¤±æ—¶é—´åˆå¹¶ä¸ºæ—¶é—´æ®µ
        missing_ranges = []
        if missing_times:
            range_start = missing_times[0]
            range_end = missing_times[0]
            
            for i in range(1, len(missing_times)):
                current_time = missing_times[i]
                expected_next = range_end + interval_delta
                
                if current_time == expected_next:
                    # è¿ç»­ç¼ºå¤±ï¼Œæ‰©å±•å½“å‰èŒƒå›´
                    range_end = current_time
                else:
                    # ä¸è¿ç»­ï¼Œä¿å­˜å½“å‰èŒƒå›´å¹¶å¼€å§‹æ–°èŒƒå›´
                    missing_ranges.append((range_start, range_end))
                    range_start = current_time
                    range_end = current_time
            
            # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
            missing_ranges.append((range_start, range_end))
        
        missing_count = len(missing_times)
        completeness = (expected_count - missing_count) / expected_count * 100
        
        print(f"âš ï¸ æ•°æ®ä¸å®Œæ•´:")
        print(f"   ç¼ºå¤±è®°å½•æ•°: {missing_count}")
        print(f"   å®Œæ•´åº¦: {completeness:.1f}%")
        print(f"   ç¼ºå¤±æ—¶é—´æ®µæ•°: {len(missing_ranges)}")
        
        for i, (start, end) in enumerate(missing_ranges[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªç¼ºå¤±æ®µ
            if start == end:
                print(f"   ç¼ºå¤±æ®µ {i+1}: {start}")
            else:
                print(f"   ç¼ºå¤±æ®µ {i+1}: {start} åˆ° {end}")
        
        if len(missing_ranges) > 5:
            print(f"   ... è¿˜æœ‰ {len(missing_ranges) - 5} ä¸ªç¼ºå¤±æ®µ")
        
        return False, missing_ranges
    
    def fill_missing_data(self, data: pd.DataFrame, symbol: str, timeframe: str, 
                         missing_ranges: List[Tuple[datetime, datetime]]) -> pd.DataFrame:
        """
        è¡¥å……ç¼ºå¤±çš„Kçº¿æ•°æ®
        
        Args:
            data: ç°æœ‰çš„Kçº¿æ•°æ®
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            missing_ranges: ç¼ºå¤±çš„æ—¶é—´æ®µåˆ—è¡¨
            
        Returns:
            è¡¥å……åçš„å®Œæ•´æ•°æ®
        """
        if not missing_ranges:
            return data
        
        print(f"ğŸ”„ å¼€å§‹è¡¥å……ç¼ºå¤±æ•°æ®...")
        cache = MarketDataCache()
        all_data = [data] if not data.empty else []
        
        for i, (start_time, end_time) in enumerate(missing_ranges):
            print(f"   è¡¥å……ç¼ºå¤±æ®µ {i+1}/{len(missing_ranges)}: {start_time} åˆ° {end_time}")
            
            # è®¡ç®—éœ€è¦è·å–çš„æ•°æ®é‡
            timeframe_minutes = {
                '1m': 1, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '4h': 240, '12h': 720, '1d': 1440,
            }
            
            if timeframe not in timeframe_minutes:
                print(f"   âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ—¶é—´æ¡†æ¶: {timeframe}")
                continue
            
            interval_minutes = timeframe_minutes[timeframe]
            duration = end_time - start_time
            expected_records = int(duration.total_seconds() / 60 / interval_minutes) + 1
            
            # æ‰©å±•æ—¶é—´èŒƒå›´ä»¥ç¡®ä¿è·å–åˆ°è¾¹ç•Œæ•°æ®
            extended_start = start_time - timedelta(hours=24)  # å‘å‰æ‰©å±•24å°æ—¶
            extended_end = end_time + timedelta(hours=24)      # å‘åæ‰©å±•24å°æ—¶
            
            try:
                # å°è¯•ä»APIè·å–æ•°æ®
                missing_data = self.fetch_ohlcv_data(
                    symbol=symbol,
                    timeframe=timeframe,
                    limit=min(expected_records + 100, 1000),  # é™åˆ¶å•æ¬¡è¯·æ±‚é‡
                    since=extended_start
                )
                
                if not missing_data.empty:
                    # è¿‡æ»¤åˆ°ç›®æ ‡æ—¶é—´èŒƒå›´
                    filtered_data = missing_data[
                        (missing_data.index >= start_time) & 
                        (missing_data.index <= end_time)
                    ]
                    
                    if not filtered_data.empty:
                        all_data.append(filtered_data)
                        print(f"   âœ… æˆåŠŸè¡¥å…… {len(filtered_data)} æ¡è®°å½•")
                        
                        # ä¿å­˜åˆ°ç¼“å­˜
                        cache.upsert(symbol, timeframe, missing_data)
                    else:
                        print(f"   âš ï¸ è·å–çš„æ•°æ®ä¸åœ¨ç›®æ ‡æ—¶é—´èŒƒå›´å†…")
                else:
                    print(f"   âŒ æœªèƒ½è·å–åˆ°æ•°æ®")
                    
            except Exception as e:
                print(f"   âŒ è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            import time
            time.sleep(0.5)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if len(all_data) > 1:
            combined_data = pd.concat(all_data, axis=0)
            # å»é‡å¹¶æ’åº
            combined_data = combined_data[~combined_data.index.duplicated(keep='first')]
            combined_data = combined_data.sort_index()
            
            print(f"âœ… æ•°æ®è¡¥å……å®Œæˆï¼Œæœ€ç»ˆæ•°æ®é‡: {len(combined_data)} æ¡")
            return combined_data
        else:
            return data
    
    def fetch_complete_data(self, symbol: str = 'ETH/USDT', timeframe: str = '4h', 
                           days: int = 730) -> pd.DataFrame:
        """
        è·å–å®Œæ•´çš„Kçº¿æ•°æ®ï¼ŒåŒ…å«å®Œæ•´æ€§æ£€æŸ¥å’Œç¼ºå¤±æ•°æ®è¡¥å……
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            days: å¤©æ•°
            
        Returns:
            å®Œæ•´çš„Kçº¿æ•°æ®
        """
        print(f"ğŸ“ˆ è·å–å®Œæ•´çš„ {symbol} {timeframe} æ•°æ® (æœ€è¿‘{days}å¤©)")
        
        # 1. é¦–å…ˆä½¿ç”¨ç°æœ‰æ–¹æ³•è·å–æ•°æ®
        data = self.fetch_recent_with_cache(symbol, timeframe, days)
        
        if data.empty:
            print("âŒ æ— æ³•è·å–åŸºç¡€æ•°æ®")
            return data
        
        # 2. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        is_complete, missing_ranges = self.check_data_integrity(data, timeframe, days)
        
        # 3. å¦‚æœæ•°æ®ä¸å®Œæ•´ï¼Œè¡¥å……ç¼ºå¤±æ•°æ®
        if not is_complete and missing_ranges:
            data = self.fill_missing_data(data, symbol, timeframe, missing_ranges)
            
            # 4. å†æ¬¡æ£€æŸ¥å®Œæ•´æ€§
            print(f"\nğŸ” è¡¥å……åå†æ¬¡æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
            final_is_complete, final_missing = self.check_data_integrity(data, timeframe, days)
            
            if final_is_complete:
                print(f"âœ… æ•°æ®è¡¥å……æˆåŠŸï¼Œç°åœ¨æ•°æ®å®Œæ•´")
            else:
                print(f"âš ï¸ ä»æœ‰ {len(final_missing)} ä¸ªæ—¶é—´æ®µç¼ºå¤±æ•°æ®")
        
        return data


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®è·å–
    fetcher = BinanceDataFetcher()
    data = fetcher.fetch_recent_data(days=7)
    
    if not data.empty:
        print("\næ•°æ®é¢„è§ˆ:")
        print(data.head())
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(data.describe())
